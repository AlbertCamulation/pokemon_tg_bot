import requests
from bs4 import BeautifulSoup
import json
import os
import time
import re
from datetime import datetime

# --- è¨­å®šè·¯å¾‘ ---
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
TRANS_FILE = os.path.join(BASE_DIR, 'data', 'chinese_translation.json')
EVENTS_FILE = os.path.join(BASE_DIR, 'data', 'events.json')

# --- ç¶²ç«™è¨­å®š ---
BASE_URL = "https://pokemon.wingzero.tw"
LIST_URL = "https://pokemon.wingzero.tw/page/event-history/tw/1"

def load_pokemon_data():
    """è®€å–ä¸­æ–‡ç¿»è­¯æª”ï¼Œå»ºç«‹ 'ä¸­æ–‡å -> ID' çš„å°ç…§è¡¨"""
    if not os.path.exists(TRANS_FILE):
        print("âŒ æ‰¾ä¸åˆ°ç¿»è­¯æª”")
        return {}
    
    with open(TRANS_FILE, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # å»ºç«‹å°ç…§è¡¨: "å¦™è›™ç¨®å­" -> "bulbasaur"
    name_to_id = {}
    for p in data:
        name = p.get('speciesName')
        pid = p.get('speciesId')
        if name and pid:
            name_to_id[name] = pid.lower()
            
            # è™•ç†ç‰¹æ®Šå½¢æ…‹ï¼Œä¾‹å¦‚ "å¦™è›™èŠ± Mega" -> å…§æ–‡å¯èƒ½åªæœƒå¯« "å¦™è›™èŠ±"
            # é€™è£¡å¯ä»¥åšä¸€äº›æ¨¡ç³ŠåŒ¹é…çš„å„ªåŒ–ï¼Œä½†å…ˆä»¥å…¨åç‚ºä¸»
    return name_to_id

def get_detail_pokemon(url, name_to_id_map):
    """é€²å…¥å…§é ï¼Œåˆ†ææ–‡ç« å…§å®¹æ‰¾å‡ºç›¸é—œçš„å¯¶å¯å¤¢ ID"""
    try:
        time.sleep(1) # ç¦®è²Œæ€§å»¶é²ï¼Œé¿å…å°ä¼ºæœå™¨é€ æˆè² æ“”
        print(f"   â””â”€â”€ æ­£åœ¨åˆ†æå…§é : {url}")
        headers = {'User-Agent': 'Mozilla/5.0'}
        resp = requests.get(url, headers=headers, timeout=10)
        
        if resp.status_code != 200:
            return []

        soup = BeautifulSoup(resp.content, 'html.parser')
        
        # å‡è¨­æ–‡ç« å…§å®¹åœ¨ article æ¨™ç±¤æˆ–ç‰¹å®šçš„ class è£¡
        # æ ¹æ“šæä¾›çš„ HTMLï¼Œå…§é é€šå¸¸æ˜¯æ¨™æº–çš„ Bootstrap çµæ§‹
        # æˆ‘å€‘ç›´æ¥æŠ“å–æ•´å€‹ä¸»è¦å…§å®¹å€å¡Šçš„æ–‡å­—
        content_div = soup.find('div', class_='col-lg-9')
        if not content_div:
            return []
            
        text_content = content_div.get_text()
        
        found_ids = set()
        
        # æ¯”å°æ‰€æœ‰å¯¶å¯å¤¢ä¸­æ–‡å (é€™æœƒç¨å¾®èŠ±é»æ™‚é–“ï¼Œä½†åœ¨ GitHub Action è·‘æ²’é—œä¿‚)
        # å„ªåŒ–ï¼šå…ˆæª¢æŸ¥æ¨™é¡Œæœ‰çš„ï¼Œå†æª¢æŸ¥å…§æ–‡
        # é€™è£¡ç°¡å–®æš´åŠ›æƒæå…§æ–‡
        
        for name, pid in name_to_id_map.items():
            # æ’é™¤å¤ªçŸ­çš„åå­—é¿å…èª¤åˆ¤ (é›–ç„¶ä¸­æ–‡åå­—é€šå¸¸é‚„å¥½)
            if len(name) < 2: continue
            
            # å¦‚æœåå­—å‡ºç¾åœ¨æ–‡ç« å…§
            if name in text_content:
                # éæ¿¾æ‰ä¸€äº›å¸¸è¦‹çš„èª¤åˆ¤ï¼Œä¾‹å¦‚ "çš®å¡ä¸˜" å¯èƒ½å‡ºç¾åœ¨ä»»ä½•æ–‡ç« 
                # ä½†æ´»å‹•é€šå¸¸å°±æ˜¯é‡å°ç‰¹å®šå¯¶å¯å¤¢ï¼Œæ‰€ä»¥å…ˆå…¨éƒ¨æŠ“é€²ä¾†
                found_ids.add(pid)
        
        # é€™è£¡å¯èƒ½æœƒæŠ“åˆ°å¤ªå¤š (ä¾‹å¦‚æ–‡ä¸­æåˆ°å‰‹åˆ¶å±¬æ€§çš„å¯¶å¯å¤¢)
        # é€šå¸¸æ´»å‹•ä¸»è§’æœƒåœ¨æ¨™é¡Œæˆ–å‡ºç¾æ¬¡æ•¸æœ€å¤šï¼Œé€™è£¡å…ˆå›å‚³æ‰€æœ‰æ‰¾åˆ°çš„
        # ç‚ºäº†é¿å…é›œè¨Šï¼Œæˆ‘å€‘é™åˆ¶ï¼šå¦‚æœæ‰¾åˆ°è¶…é 5 éš»ï¼Œå¯èƒ½æ˜¯ä¸€èˆ¬æ–°èï¼Œä¸æ˜¯ç‰¹å®šå¯¶å¯å¤¢æ´»å‹•
        # é™¤éæ˜¯ "ç¤¾ç¾¤æ—¥" é€™ç¨®æ¨™é¡Œ
        
        return list(found_ids)

    except Exception as e:
        print(f"   âŒ å…§é åˆ†æéŒ¯èª¤: {e}")
        return []

def fetch_events():
    name_to_id = load_pokemon_data()
    headers = {'User-Agent': 'Mozilla/5.0'}
    
    print(f"ğŸ” é–‹å§‹çˆ¬å–åˆ—è¡¨: {LIST_URL}")
    resp = requests.get(LIST_URL, headers=headers)
    if resp.status_code != 200:
        print("âŒ ç„¡æ³•è®€å–ç¶²ç«™")
        return []
    
    soup = BeautifulSoup(resp.content, 'html.parser')
    
    event_list = soup.select('div.col-lg-9 ul.list-unstyled li.py-3')
    
    events_data = []
    
    for li in event_list:
        h3 = li.find('h3')
        if not h3: continue
        
        # 1. æŠ“æ¨™é¡Œ
        raw_title = h3.get_text().strip()
        
        # 2. æŠ“è©³ç´°é€£çµ
        a_tag = h3.find('a')
        detail_url = ""
        if a_tag and 'href' in a_tag.attrs:
            detail_url = BASE_URL + a_tag['href']
            
        # 3. æŠ“æ™‚é–“ (â˜…â˜…â˜… ä¿®æ”¹é‡é» â˜…â˜…â˜…)
        time_tag = li.find('time')
        date_str = ""
        raw_date_str = ""
        if time_tag:
            raw_date_str = time_tag.get_text().strip()
            # æŠ“å–æ‰€æœ‰æ—¥æœŸæ ¼å¼
            dates = re.findall(r'(\d{4}-\d{2}-\d{2})', raw_date_str)
            
            if len(dates) >= 2:
                # å¦‚æœé–‹å§‹å’ŒçµæŸæ—¥æœŸä¸åŒï¼Œé¡¯ç¤ºç¯„åœ
                if dates[0] != dates[1]:
                    date_str = f"{dates[0]} ~ {dates[1]}"
                else:
                    date_str = dates[0]
            elif len(dates) == 1:
                date_str = dates[0]
            else:
                date_str = raw_date_str # è¬ä¸€æ ¼å¼å¾ˆæ€ªï¼Œå°±é¡¯ç¤ºåŸæ–‡
        
        print(f"ğŸ“… ç™¼ç¾æ´»å‹•: {raw_title} ({date_str})")
        
        # 4. åˆ¤æ–·å¯¶å¯å¤¢ ID (ä¿æŒä¸è®Š)
        pokemon_ids = []
        for name, pid in name_to_id.items():
            if name in raw_title:
                pokemon_ids.append(pid)
        
        if not pokemon_ids and detail_url:
            keywords = ["ç¤¾ç¾¤æ—¥", "èšç„¦æ™‚åˆ»", "åœ˜é«”æˆ°", "èª¿æŸ¥", "å­µåŒ–", "å°æˆ°æ—¥", "æ¥µå·¨"]
            if any(k in raw_title for k in keywords):
                ids_in_detail = get_detail_pokemon(detail_url, name_to_id)
                pokemon_ids.extend(ids_in_detail)
        
        pokemon_ids = list(set(pokemon_ids))
        
        if pokemon_ids or any(k in raw_title for k in ["ç¤¾ç¾¤æ—¥", "èšç„¦æ™‚åˆ»"]):
            events_data.append({
                "date": date_str,      # é€™è£¡ç¾åœ¨æœƒæ˜¯ "2025-12-22 ~ 2025-12-31"
                "raw_time": raw_date_str,
                "pokemonId": pokemon_ids,
                "eventName": raw_title,
                "link": detail_url
            })

    return events_data

def save_events(events):
    with open(EVENTS_FILE, 'w', encoding='utf-8') as f:
        json.dump(events, f, ensure_ascii=False, indent=2)
    print(f"âœ… å·²æ›´æ–° {len(events)} ç­†æ´»å‹•è‡³ {EVENTS_FILE}")

if __name__ == "__main__":
    data = fetch_events()
    if data:
        save_events(data)
