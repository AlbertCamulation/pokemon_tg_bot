import requests
from bs4 import BeautifulSoup
import json
import os
import re
from datetime import datetime

# --- è¨­å®šè·¯å¾‘ ---
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
TRANS_FILE = os.path.join(BASE_DIR, 'data', 'chinese_translation.json')
EVENTS_FILE = os.path.join(BASE_DIR, 'data', 'events.json')

# --- ç¶²ç«™è¨­å®š ---
BASE_URL = "https://pokemon.wingzero.tw"
LIST_URL = "https://pokemon.wingzero.tw/page/event-history/tw/1"

def load_pokemon_data():
    """å»ºç«‹ ä¸­æ–‡åç¨± -> ID çš„å°ç…§è¡¨"""
    if not os.path.exists(TRANS_FILE):
        return {}
    
    with open(TRANS_FILE, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    name_to_id = {}
    for p in data:
        name = p.get('speciesName')
        pid = p.get('speciesId')
        if name and pid:
            name_to_id[name] = pid.lower()
            # è™•ç†ç‰¹æ®Šå½¢æ…‹ (ä¾‹å¦‚ "ç«ç´…ä¸å€’ç¿" å¯èƒ½å°æ‡‰åˆ° "darumaka_galarian" æˆ–åŸç‰ˆ)
            # é€™è£¡ç°¡å–®è™•ç†ï¼Œå¦‚æœæ˜¯ "æ¥µå·¨åŒ– æµ·è±¹çƒ"ï¼Œæˆ‘å€‘åªè¦å°åˆ° "æµ·è±¹çƒ" å³å¯
    return name_to_id

def parse_monthly_article(url, name_to_id, current_year):
    """å°ˆé–€è§£æã€Œæœˆåº¦æ´»å‹•ç¸½è¦½ã€æ–‡ç« çš„å…§æ–‡"""
    print(f"   â””â”€â”€ é€²å…¥æœˆåº¦æ–‡ç« åˆ†æ: {url}")
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        resp = requests.get(url, headers=headers, timeout=10)
        if resp.status_code != 200: return []

        soup = BeautifulSoup(resp.content, 'html.parser')
        content_div = soup.find('div', class_='col-lg-9') # å‡è¨­æ–‡ç« å…§å®¹åœ¨é€™è£¡
        if not content_div: return []

        # å–å¾—ç´”æ–‡å­—å…§å®¹ï¼ŒæŒ‰è¡Œåˆ†å‰²
        text_lines = content_div.get_text("\n").split("\n")
        
        extracted_events = []
        current_category = ""
        
        # å®šç¾©æˆ‘å€‘è¦æŠ“çš„å€å¡Šé—œéµå­—
        target_categories = ["æ¥µå·¨å°æˆ°", "æ¥µå·¨æ˜ŸæœŸä¸€", "å‚³èªªåœ˜é«”æˆ°", "è¶…ç´šåœ˜é«”æˆ°", "æš—å½±å‚³èªªåœ˜é«”æˆ°"]
        
        # æ—¥æœŸæ­£å‰‡ (æ”¯æ´ 12/1, 12/22, 1/4 ç­‰æ ¼å¼)
        date_pattern = re.compile(r'(\d{1,2}/\d{1,2})[ï½~-](\d{1,2}/\d{1,2})')

        for line in text_lines:
            line = line.strip()
            if not line: continue

            # 1. åˆ¤æ–·ç•¶å‰æ®µè½æ˜¯ä»€éº¼é¡å‹ (ä¾‹å¦‚ "æ¥µå·¨å°æˆ° & æ¥µå·¨æ˜ŸæœŸä¸€")
            for cat in target_categories:
                if cat in line:
                    current_category = cat
                    # ç°¡åŒ–åç¨±
                    if "æ¥µå·¨" in cat: current_category = "æ¥µå·¨å°æˆ°"
                    elif "å‚³èªª" in cat and "æš—å½±" not in cat: current_category = "å‚³èªªåœ˜é«”æˆ°"
                    elif "è¶…ç´š" in cat: current_category = "è¶…ç´šåœ˜é«”æˆ°"
                    elif "æš—å½±" in cat: current_category = "æš—å½±å‚³èªªåœ˜é«”æˆ°"
                    break
            
            # å¦‚æœé‚„æ²’é€²åˆ°æˆ‘å€‘è¦çš„å€å¡Šï¼Œå°±è·³é
            if not current_category: continue

            # 2. å˜—è©¦æŠ“å–æ—¥æœŸç¯„åœ (ä¾‹å¦‚ "12/22ï½12/28")
            date_match = date_pattern.search(line)
            if date_match:
                start_date_raw = date_match.group(1) # 12/22
                end_date_raw = date_match.group(2)   # 12/28
                
                # è½‰æ›æˆå®Œæ•´æ—¥æœŸæ ¼å¼ YYYY-MM-DD
                # æ³¨æ„è·¨å¹´å•é¡Œï¼šå¦‚æœç•¶å‰æ˜¯ 12æœˆï¼Œä½†æŠ“åˆ° 1æœˆï¼Œå¹´ä»½è¦+1
                def parse_partial_date(d_str, year):
                    m, d = map(int, d_str.split('/'))
                    # ç°¡å–®åˆ¤æ–·è·¨å¹´ï¼šå¦‚æœæœˆä»½æ¯”ç¾åœ¨å°å¾ˆå¤š (ä¾‹å¦‚ç¾åœ¨12æœˆï¼ŒæŠ“åˆ°1æœˆ)ï¼Œå¹´ä»½+1
                    # é€™è£¡ç°¡åŒ–ï¼šå‡è¨­æ–‡ç« æ¨™é¡Œçš„å¹´ä»½æ˜¯æº–çš„
                    target_year = year
                    if m == 1 and datetime.now().month == 12: # è·¨å¹´ä¿®æ­£
                        target_year += 1
                    return f"{target_year}-{m:02d}-{d:02d}"

                # å˜—è©¦åœ¨åŒä¸€è¡Œæˆ–ä¸‹ä¸€è¡Œæ‰¾å¯¶å¯å¤¢åç¨±
                # é€™è£¡æˆ‘å€‘ç°¡å–®åšï¼šæª¢æŸ¥é€™è¡Œæœ‰æ²’æœ‰å¯¶å¯å¤¢ï¼Œå¦‚æœæ²’æœ‰ï¼Œå°±å¾€ä¸‹çœ‹å¹¾è¡Œ
                # ä½†é€šå¸¸æ ¼å¼æ˜¯ï¼š
                # 12/22ï½12/28
                # æ¥µå·¨åŒ– æµ·è±¹çƒ â˜…
                
                # æš«å­˜é€™å€‹æ—¥æœŸï¼Œå¾€ä¸‹æ‰¾å¯¶å¯å¤¢
                found_pokemons = []
                
                # å¾€é€™è¡Œè£¡é¢æ‰¾
                for name, pid in name_to_id.items():
                    if name in line and pid not in found_pokemons:
                         found_pokemons.append(pid)
                
                # å¦‚æœé€™è¡Œæ²’æ‰¾åˆ°ï¼Œé€šå¸¸åœ¨ä¸‹é¢å¹¾è¡Œ (æˆ–æ˜¯åŒä¸€è¡Œå¾Œé¢)
                # é€™è£¡ç‚ºäº†ç°¡å–®ï¼Œæˆ‘å€‘å‡è¨­å¦‚æœé€™è¡Œæœ‰æ—¥æœŸä½†æ²’å¯¶å¯å¤¢ï¼Œå°±æ¨™è¨˜ä¸€ä¸‹ï¼Œ
                # ä½†çˆ¬èŸ²é‚è¼¯å¤ªè¤‡é›œæœƒå®¹æ˜“éŒ¯ï¼Œæˆ‘å€‘é€™è£¡æ¡ç”¨ã€Œé€è¡Œæƒæã€ç­–ç•¥ï¼š
                # å¦‚æœä¸€è¡Œæœ‰æ—¥æœŸï¼Œæˆ‘å€‘å°±é æœŸæ¥ä¸‹ä¾†çš„å¹¾è¡Œæ˜¯å¯¶å¯å¤¢ï¼Œç›´åˆ°é‡åˆ°ä¸‹ä¸€å€‹æ—¥æœŸæˆ–ç©ºè¡Œ
                
                # ä¿®æ­£ç­–ç•¥ï¼š
                # ç•¶è®€åˆ°æ—¥æœŸæ™‚ï¼Œå»ºç«‹ä¸€å€‹ pending event
                # ç•¶è®€åˆ°å¯¶å¯å¤¢æ™‚ï¼ŒæŠŠå®ƒåŠ å…¥æœ€è¿‘çš„ä¸€å€‹ pending event
                
                start_date_fmt = parse_partial_date(start_date_raw, current_year)
                end_date_fmt = parse_partial_date(end_date_raw, current_year)
                
                # å»ºç«‹ä¸€å€‹æ–°æ´»å‹•ç‰©ä»¶
                extracted_events.append({
                    "date": f"{start_date_fmt} ~ {end_date_fmt}",
                    "raw_time": line,
                    "pokemonId": found_pokemons, # å¯èƒ½ç‚ºç©ºï¼Œå¾…å¡«è£œ
                    "eventName": f"{current_category}", # æš«å®šåç¨±
                    "link": url,
                    "is_pending": True # æ¨™è¨˜é‚„éœ€è¦æ‰¾å¯¶å¯å¤¢
                })
            
            elif extracted_events and extracted_events[-1]["is_pending"]:
                # 3. å¦‚æœä¸Šä¸€å€‹æ´»å‹•é‚„åœ¨æ‰¾å¯¶å¯å¤¢ï¼Œå°±åœ¨é€™è¡Œæ‰¾
                last_event = extracted_events[-1]
                
                # æ‰¾å¯¶å¯å¤¢
                found_in_line = []
                for name, pid in name_to_id.items():
                    # æ’é™¤å¤ªçŸ­çš„å¹²æ“¾å­—ï¼Œä¾‹å¦‚ "æ¥µå·¨åŒ–" ä¸æ˜¯å¯¶å¯å¤¢
                    if name in line:
                        last_event["pokemonId"].append(pid)
                        found_in_line.append(name)
                
                if found_in_line:
                    # å¦‚æœæ‰¾åˆ°äº†ï¼Œæ›´æ–°æ´»å‹•åç¨±
                    # ä¾‹å¦‚ "æ¥µå·¨å°æˆ°ï¼šæµ·è±¹çƒ"
                    p_names = "ã€".join(found_in_line)
                    last_event["eventName"] = f"{last_event['eventName']}ï¼š{p_names}"
                    # ä¸æŠŠ is_pending è¨­ç‚º Falseï¼Œå› ç‚ºå¯èƒ½é‚„æœ‰å…¶ä»–éš» (ä¾‹å¦‚ä¸‰åŠå®¢)
                
                # å¦‚æœé‡åˆ°ç©ºè¡Œæˆ–æ˜¯æ–°çš„æ—¥æœŸï¼Œé€™å€‹ event å°±çµæŸäº† (åœ¨è¿´åœˆé–‹é ­æœƒè™•ç†æ—¥æœŸ)
                # é€™è£¡ä¸åšç‰¹åˆ¥çµæŸå‹•ä½œï¼Œé ä¸‹ä¸€å€‹æ—¥æœŸä¾†åˆ‡æ–·

        # æ•´ç†çµæœï¼šç§»é™¤æ²’æœ‰æ‰¾åˆ°å¯¶å¯å¤¢çš„æ´»å‹•
        final_list = []
        for evt in extracted_events:
            if evt["pokemonId"]:
                del evt["is_pending"] # ç§»é™¤å…§éƒ¨æ¨™è¨˜
                evt["pokemonId"] = list(set(evt["pokemonId"])) # å»é‡
                final_list.append(evt)
                
        return final_list

    except Exception as e:
        print(f"   âŒ è§£ææ–‡ç« éŒ¯èª¤: {e}")
        return []

def fetch_events():
    name_to_id = load_pokemon_data()
    headers = {'User-Agent': 'Mozilla/5.0'}
    
    print(f"ğŸ” é–‹å§‹çˆ¬å–åˆ—è¡¨: {LIST_URL}")
    resp = requests.get(LIST_URL, headers=headers)
    if resp.status_code != 200: return []
    
    soup = BeautifulSoup(resp.content, 'html.parser')
    event_list = soup.select('div.col-lg-9 ul.list-unstyled li.py-3')
    
    events_data = []
    
    # å–å¾—ä»Šå¹´å¹´ä»½ï¼Œç”¨æ–¼è§£ææ—¥æœŸ
    current_year = datetime.now().year

    for li in event_list:
        h3 = li.find('h3')
        if not h3: continue
        
        raw_title = h3.get_text().strip()
        
        a_tag = h3.find('a')
        detail_url = ""
        if a_tag and 'href' in a_tag.attrs:
            detail_url = BASE_URL + a_tag['href']
            
        time_tag = li.find('time')
        date_str = ""
        raw_date_str = ""
        
        # --- è™•ç†ä¸€èˆ¬åˆ—è¡¨é …ç›® (ä¿æŒåŸæœ‰é‚è¼¯) ---
        if time_tag:
            raw_date_str = time_tag.get_text().strip()
            dates = re.findall(r'(\d{4}-\d{2}-\d{2})', raw_date_str)
            if len(dates) >= 2:
                date_str = f"{dates[0]} ~ {dates[1]}" if dates[0] != dates[1] else dates[0]
            elif len(dates) == 1:
                date_str = dates[0]
            else:
                date_str = raw_date_str

        # 1. ä¸€èˆ¬æ´»å‹•è™•ç†
        pokemon_ids = []
        for name, pid in name_to_id.items():
            if name in raw_title:
                pokemon_ids.append(pid)
        
        # å¦‚æœæ˜¯ã€Œæœˆåº¦æ´»å‹•ç¸½è¦½ã€æ–‡ç« ï¼Œå°±ä½¿ç”¨æ–°é‚è¼¯è§£æ
        # æ¨™é¡Œé€šå¸¸æ˜¯ "PokÃ©mon GO 2025 å¹´ 12 æœˆæ´»å‹•"
        if "æœˆæ´»å‹•" in raw_title and detail_url:
            print(f"ğŸ“… ç™¼ç¾æœˆåº¦ç¸½è¦½: {raw_title}")
            # å‘¼å«æ–°å‡½æ•¸è§£æå…§æ–‡
            monthly_events = parse_monthly_article(detail_url, name_to_id, current_year)
            events_data.extend(monthly_events)
            continue # è·³éåŸæœ¬çš„è™•ç†ï¼Œå› ç‚ºå·²ç¶“è™•ç†å®Œå…§æ–‡äº†

        # ä¸€èˆ¬æ´»å‹•çš„è©³ç´°é é¢çˆ¬å– (ç¤¾ç¾¤æ—¥ç­‰)
        if not pokemon_ids and detail_url:
            keywords = ["ç¤¾ç¾¤æ—¥", "èšç„¦æ™‚åˆ»", "åœ˜é«”æˆ°", "èª¿æŸ¥", "å­µåŒ–", "å°æˆ°æ—¥"]
            if any(k in raw_title for k in keywords):
                # é€™è£¡å¯ä»¥ä½¿ç”¨ç°¡å–®çš„å…§æ–‡é—œéµå­—çˆ¬å– (å¦‚æœæ‚¨åŸä¾†çš„ get_detail_pokemon é‚„åœ¨çš„è©±)
                # æˆ–æ˜¯ä¾è³´æ¨™é¡Œå³å¯
                pass 
        
        if pokemon_ids or any(k in raw_title for k in ["ç¤¾ç¾¤æ—¥", "èšç„¦æ™‚åˆ»"]):
            events_data.append({
                "date": date_str,
                "raw_time": raw_date_str,
                "pokemonId": list(set(pokemon_ids)),
                "eventName": raw_title,
                "link": detail_url
            })

    return events_data

def save_events(events):
    with open(EVENTS_FILE, 'w', encoding='utf-8') as f:
        json.dump(events, f, ensure_ascii=False, indent=2)
    print(f"âœ… å·²æ›´æ–° {len(events)} ç­†æ´»å‹•è‡³ {EVENTS_FILE}")

if __name__ == "__main__":
    data = fetch_events()
    if data:
        save_events(data)
